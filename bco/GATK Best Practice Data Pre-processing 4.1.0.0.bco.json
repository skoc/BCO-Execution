{
  "bco_spec_version": "https://w3id.org/biocompute/1.3.0/",
  "bco_id": "https://biocompute.sbgenomics.com/bco/c44fe6d4-5d5c-499e-a247-394fdbde7725",
  "checksum": "37aeccab78804893d2f309670d51f021a5b9466a33155aa7574b0e07587bf644",
  "provenance_domain": {
    "name": "BROAD Best Practice Data Pre-processing Workflow 4.1.0.0",
    "version": "1.0.14",
    "review": [],
    "derived_from": "uros_sipetic/broad-best-practice-data-pre-processing-4-1-0-0-demo/broad-best-practice-data-pre-processing-workflow-4-1-0-0/14",
    "obsolete_after": "2021-06-10T00:00:00+0000",
    "embargo": ["2021-06-10T00:00:00+0000", "2021-06-10T00:00:00+0000"],
    "created": "2021-06-10T00:00:00+0000",
    "modified": "2021-06-10T00:00:00+0000",
    "contributors": [],
    "license": "https://spdx.org/licenses/CC-BY-4.0.html"
  },
  "usability_domain": "",
  "extension_domain": {
    "fhir_extension": {
      "fhir_endpoint": "",
      "fhir_version": "",
      "fhir_resources": {}
    },
    "scm_extension": {
      "scm_repository": "",
      "scm_type": "git",
      "scm_commit": "",
      "scm_path": "",
      "scm_preview": ""
    }
  },
  "description_domain": {
    "keywords": [],
    "xref": [],
    "platform": "Seven Bridges Platform",
    "pipeline_steps": [
      {
        "step_number": "1",
        "name": "bwa_mem_bundle_0_7_15",
        "description": "**BWA MEM** is an algorithm designed for aligning sequence reads onto a large reference genome. BWA MEM is implemented as a component of BWA. The algorithm can automatically choose between performing end-to-end and local alignments. BWA MEM is capable of outputting multiple alignments, and finding chimeric reads. It can be applied to a wide range of read lengths, from 70 bp to several megabases. \n\nIn order to obtain possibilities for additional fast processing of aligned reads, two tools are embedded together into the same package with BWA MEM (0.7.13): Samblaster. (0.1.22) and Sambamba (v0.6.0). \nIf deduplication of alignments is needed, it can be done by setting the parameter 'Duplication'. **Samblaster** will be used internally to perform this action.\nBesides the standard BWA MEM SAM output file, BWA MEM package has been extended to support two additional output options: a BAM file obtained by piping through **Sambamba view** while filtering out the secondary alignments, as well as a Coordinate Sorted BAM option that additionally pipes the output through **Sambamba sort**, along with an accompanying .bai file produced by **Sambamba sort** as side effect. Sorted BAM is the default output of BWA MEM. Parameters responsible for these additional features are 'Filter out secondary alignments' and 'Output format'. Passing data from BWA MEM to Samblaster and Sambamba tools has been done through the pipes which saves processing times of two read and write of aligned reads into the hard drive. \n\nFor input reads fastq files of total size less than 10 GB we suggest using the default setting for parameter 'total memory' of 15GB, for larger files we suggest using 58 GB of memory and 32 CPU cores.\n\n**Important:**\nIn order to work BWA MEM Bundle requires fasta reference file accompanied with **bwa fasta indices** in TAR file.\nThere is the **known issue** with samblaster. It does not support processing when number of sequences in fasta is larger than 32768. If this is the case do not use deduplication option because the output BAM will be corrupted.\n\nHuman reference genome version 38 comes with ALT contigs, a collection of diverged alleles present in some humans but not the others. Making effective use of these contigs will help to reduce mapping artifacts, however, to facilitate mapping these ALT contigs to the primary assembly, GRC decided to add to each contig long flanking sequences almost identical to the primary assembly. As a result, a naive mapping against GRCh38+ALT will lead to many mapQ-zero mappings in these flanking regions. Please use post-processing steps to fix these alignments or implement [steps](https://sourceforge.net/p/bio-bwa/mailman/message/32845712/) described by the author of BWA toolkit.",
        "version": "0.7.15",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "2",
        "name": "gatk_applybqsr_4_1_0_0",
        "description": "The **GATK ApplyBQSR** tool recalibrates the base qualities score of the input reads and outputs a recalibrated BAM, SAM or CRAM file. \n\nThis tool performs the second pass in a two-stage process called Base Quality Score Recalibration (BQSR). Specifically, it recalibrates the base qualities of the input reads based on the recalibration table produced by the **BaseRecalibrator** tool. The goal of this procedure is to correct systematic biasses that affect the assignment of base quality scores by the sequencer. The first pass consists of calculating error empirically and finding patterns in how error varies with basecall features over all bases. The relevant observations are written to the recalibration table. The second pass consists of applying numerical corrections to each individual basecall based on the patterns identified in the first step (recorded in the recalibration table) and write out the recalibrated data to a new BAM, SAM or CRAM file [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of the page.*\n\n###Common Use Cases\n\n* The **GATK ApplyBQSR** tool requires the BAM, SAM or CRAM file on its **Input BAM/SAM/CRAM file** (`--input`) input and the covariates table (= recalibration file) generated by the **BaseRecalibrator** tool on its **BQSR recal file** input (`--bqsr-recal-file`). The tool generates on its **Output BAM/SAM/CRAM** output a new alignments file which contains recalibrated read data.\n\n* Usage example\n\n```\n gatk ApplyBQSR \\\n   --reference reference.fasta \\\n   --input input.bam \\\n   --bqsr-recal-file recalibration.table \\\n   --output output.bam\n\n```\n\n* If the input alignments file is in CRAM format, the reference sequence is required on the **Reference sequence** (`--reference`) input of the tool.\n\n* Original qualities can be retained in the output file under the \"OQ\" tag if desired. See the **Emit original quals** (`--emit-original-quals`) argument for details.\n\n###Changes Introduced by Seven Bridges\n\n* All output files will be prefixed using the **Output prefix** parameter. In case **Output prefix** is not provided, output prefix will be the same as the Sample ID metadata from **Input SAM/BAM/CRAM file**, if the Sample ID metadata exists. Otherwise, output prefix will be inferred from the **Input SAM/BAM/CRAM** filename. This way, having identical names of the output files between runs is avoided. Moreover,  **recalibrated** will be added before the extension of the output file name. \n\n* The user has a possibility to specify the output file format using the **Output file format** argument. Otherwise, the output file format will be the same as the format of the input file.\n\n* **Include intervals** (`--intervals`) option is divided into **Include intervals string** and **Include intervals file** options.\n\n* **Exclude intervals** (`--exclude-intervals`) option is divided into **Exclude intervals string** and **Exclude intervals file** options.\n\n###Common Issues and Important Notes\n\n* Note: This tool replaces the use of PrintReads for the application of base quality score recalibration as practiced in earlier versions of GATK (2.x and 3.x) [1].\n* Note: You should only run **ApplyBQSR** with the covariates table created from the input BAM, SAM or CRAM file [1].\nInput BAM/SAM/CRAM file\n* Note: If **Read filter** (`--read-filter`) option is set to \"LibraryReadFilter\", **Library** (`--library`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"PlatformReadFilter\", **Platform filter name** (`--platform-filter-name`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to\"PlatformUnitReadFilter\", **Black listed lanes** (`--black-listed-lanes`) option must be set to some value. \n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadGroupBlackListReadFilter\", **Read group black list** (`--read-group-black-list`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadGroupReadFilter\", **Keep read group** (`--keep-read-group`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadLengthReadFilter\", **Max read length** (`--max-read-length`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadNameReadFilter\", **Read name** (`--read-name`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadStrandFilter\", **Keep reverse strand only** (`--keep-reverse-strand-only`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"SampleReadFilter\", **Sample** (`--sample`) option must be set to some value.\n\n###Performance Benchmarking\n\nBelow is a table describing runtimes and task costs of **GATK ApplyBQSR** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Input size | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|\n|     RNA-Seq     |  2.2 GB |   7min   | ~0.05$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     |  6.6 GB |   22min   | ~0.12$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 11 GB |  36min  | ~0.17$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 22 GB |  1h 15min  | ~0.29$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n###References\n\n[1] [GATK ApplyBQSR](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_bqsr_ApplyBQSR.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "3",
        "name": "gatk_baserecalibrator_4_1_0_0",
        "description": "The **GATK BaseRecalibrator** tool performs first pass of Base Quality Score Recalibration (BQSR) based on various covariates. The default covariates are read group, reported quality score, machine cycle, and nucleotide context. The tool generates on a recalibration table on its output.\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of the page.*\n\n###Common Use Cases\n\n* The **GATK BaseRecalibrator** tool requires the input read data whose quality scores need to be assessed on its **Input BAM/SAM/CRAM file** (`--input`) input and the database of known polymorphic sites to skip over on its **Known SNPs** and **Known INDELs** (`--known-sites`) inputs. The tool generates on its **Output recalibration report** output a GATK report file with many tables: the list of arguments, the quantized qualities table, the recalibration table by read group, the recalibration table by quality score,\nthe recalibration table for all the optional covariates.\n\n* Usage example:\n\n```\ngatk BaseRecalibrator \\\n   --input my_reads.bam \\\n   --reference reference.fasta \\\n   --known-sites sites_of_variation.vcf \\\n   --known-sites another/optional/setOfSitesToMask.vcf \\\n   --output recal_data.table\n\n```\n\n###Changes Introduced by Seven Bridges\n\n* All output files will be prefixed using the **Output prefix** parameter. In case **Output prefix** is not provided, output prefix will be the same as the Sample ID metadata from **Input SAM/BAM/CRAM file**, if the Sample ID metadata exists. Otherwise, output prefix will be inferred from the **Input SAM/BAM/CRAM** filename. This way, having identical names of the output files between runs is avoided. Moreover,  **recal_data** will be added before the extension of the output file name which is CSV by default. \n\n* **Include intervals** (`--intervals`) option is divided into **Include intervals string** and **Include intervals file** options.\n\n* **Exclude intervals** (`--exclude-intervals`) option is divided into **Exclude intervals string** and **Exclude intervals file** options.\n\n###Common Issues and Important Notes\n\n* Note: If **Read filter** (`--read-filter`) option is set to \"LibraryReadFilter\", **Library** (`--library`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"PlatformReadFilter\", **Platform filter name** (`--platform-filter-name`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to\"PlatformUnitReadFilter\", **Black listed lanes** (`--black-listed-lanes`) option must be set to some value. \n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadGroupBlackListReadFilter\", **Read group black list** (`--read-group-black-list`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadGroupReadFilter\", **Keep read group** (`--keep-read-group`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadLengthReadFilter\", **Max read length** (`--max-read-length`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadNameReadFilter\", **Read name** (`--read-name`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"ReadStrandFilter\", **Keep reverse strand only** (`--keep-reverse-strand-only`) option must be set to some value.\n* Note: If **Read filter** (`--read-filter`) option is set to \"SampleReadFilter\", **Sample** (`--sample`) option must be set to some value.\n\n###Performance Benchmarking\n\nBelow is a table describing runtimes and task costs of **GATK BaseRecalibrator** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Input size | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|\n|     RNA-Seq     |  2.2 GB |   8min   | ~0.05$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     |  6.6 GB |   18min   | ~0.12$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 11 GB |  26min  | ~0.17$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 22 GB |  45min  | ~0.29$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n###References\n\n[1] [GATK BaseRecalibrator](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_bqsr_BaseRecalibrator.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "4",
        "name": "gatk_createsequencegroupingtsv_4_1_0_0",
        "description": "**CreateSequenceGroupingTSV** tool generate sets of intervals for scatter-gathering over chromosomes.\n\nIt takes **Reference dictionary** file (`--ref_dict`) as an input and creates files which contain chromosome names grouped based on their sizes.\n\n\n###**Common Use Cases**\n\nThe tool has only one input (`--ref_dict`) which is required and has no additional arguments. **CreateSequenceGroupingTSV** tool results are **Sequence Grouping** file which is a text file containing chromosome groups, and **Sequence Grouping with Unmapped**, a text file which has the same content as **Sequence Grouping** with additional line containing \"unmapped\" string.\n\n\n* Usage example\n\n\n```\npython CreateSequenceGroupingTSV.py \n      --ref_dict example_reference.dict\n\n```\n\n\n\n###**Changes Introduced by Seven Bridges**\n\nPython code provided within WGS Germline WDL was adjusted to be called as a script (`CreateSequenceGroupingTSV.py`).\n\n\n###**Common Issues and Important Notes**\n\nNone.\n\n\n### Reference\n[1] [CreateSequenceGroupingTSV](https://github.com/gatk-workflows/broad-prod-wgs-germline-snps-indels/blob/master/PairedEndSingleSampleWf-fc-hg38.wdl)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "5",
        "name": "gatk_gatherbamfiles_4_1_0_0",
        "description": "**GATK GatherBamFiles** concatenates one or more BAM files resulted form scattered paralel anaysis. \n\n\n### Common Use Cases \n\n* **GATK GatherBamFiles**  tool performs a rapid \"gather\" or concatenation on BAM files into single BAM file. This is often needed in operations that have been run in parallel across genomics regions by scattering their execution across computing nodes and cores thus resulting in smaller BAM files.\n* Usage example:\n```\n\njava -jar picard.jar GatherBamFiles\n      --INPUT=input1.bam\n      --INPUT=input2.bam\n```\n\n### Common Issues and Important Notes\n* **GATK GatherBamFiles** assumes that the list of BAM files provided as input are in the order that they should be concatenated and simply links the bodies of the BAM files while retaining the header from the first file. \n*  Operates by copying the gzip blocks directly for speed but also supports the generation of an MD5 in the output file and the indexing of the output BAM file.\n* This tool only support BAM files. It does not support SAM files.\n\n###Changes Intorduced by Seven Bridges\n* Generated output BAM file will be prefixed using the **Output prefix** parameter. In case the **Output prefix** is not provided, the output prefix will be the same as the **Sample ID** metadata from the **Input alignments**, if the **Sample ID** metadata exists. Otherwise, the output prefix will be inferred from the **Input alignments** filename. This way, having identical names of the output files between runs is avoided.",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "6",
        "name": "gatk_gatherbqsrreports_4_1_0_0",
        "description": "**GATK GatherBQSRReports** gathers scattered BQSR recalibration reports from parallelized base recalibration runs into a single file.\nThe combination is done simply by adding up all observations and errors.\n\n\n### Common Use Cases \n\n* This tool is intended to be used to combine recalibration tables from runs of BaseRecalibrator parallelized per-interval.\n\n* Usage example (input BAM file is single-end):\n\n```\ngatk GAtherBQSRReports \n     --input example1.csv\n     --input example2.csv\n```\n\n\n### Common Issues and Important Notes\n\n* This method DOES NOT recalculate the empirical qualities and quantized qualities. You have to recalculate them after combining. The reason for not calculating it is because this function is intended for combining a series of recalibration reports, and it only makes sense to calculate the empirical qualities and quantized qualities after all the recalibration reports have been combined. This is done to make the tool faster.\nThe reported empirical quality is recalculated.\n\n###Changes Introduced by Seven Bridges\n\n* Output file will be prefixed using the **Output prefix** parameter. In case **Output prefix** is not provided, output prefix will be the same as the **Sample ID** metadata from the **Input bqsr reports**, if the **Sample ID** metadata exists. Otherwise, output prefix will be inferred from the **Input bqsr reports** filename. This way, having identical names of the output files between runs is avoided. Moreover,  **.recal_data.csv** will be added before the extension of the output file name. \n\n\n###References\n\n[1] [GATK GatherBQSRReports](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_bqsr_GatherBQSRReports.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "7",
        "name": "gatk_markduplicates_4_1_0_0",
        "description": "The **GATK  MarkDuplicates** tool identifies duplicate reads in a BAM or SAM file.\n\nThis tool locates and tags duplicate reads in a BAM or SAM file, where duplicate reads are defined as originating from a single fragment of DNA. Duplicates can arise during sample preparation e.g. library construction using PCR. Duplicate reads can also result from a single amplification cluster, incorrectly detected as multiple clusters by the optical sensor of the sequencing instrument. These duplication artifacts are referred to as optical duplicates [1].\n\nThe MarkDuplicates tool works by comparing sequences in the 5 prime positions of both reads and read-pairs in the SAM/BAM file. The **Barcode tag** (`--BARCODE_TAG`) option is available to facilitate duplicate marking using molecular barcodes. After duplicate reads are collected, the tool differentiates the primary and duplicate reads using an algorithm that ranks reads by the sums of their base-quality scores (default method).\n\n\n###Common Use Cases\n\n* The **GATK MarkDuplicates** tool requires the BAM or SAM file on its **Input BAM/SAM file** (`--INPUT`) input. The tool generates a new SAM or BAM file on its **Output BAM/SAM** output, in which duplicates have been identified in the SAM flags field for each read. Duplicates are marked with the hexadecimal value of 0x0400, which corresponds to a decimal value of 1024. If you are not familiar with this type of annotation, please see the following [blog post](https://software.broadinstitute.org/gatk/blog?id=7019) for additional information. **MarkDuplicates** also produces a metrics file on its **Output metrics file** output, indicating the numbers of duplicates for both single and paired end reads.\n\n* The program can take either coordinate-sorted or query-sorted inputs, however the behavior is slightly different. When the input is coordinate-sorted, unmapped mates of mapped records and supplementary/secondary alignments are not marked as duplicates. However, when the input is query-sorted (actually query-grouped), then unmapped mates and secondary/supplementary reads are not excluded from the duplication test and can be marked as duplicate reads.\n\n* If desired, duplicates can be removed using the **Remove duplicates** (`--REMOVE_DUPLICATES`) and **Remove sequencing duplicates** ( `--REMOVE_SEQUENCING_DUPLICATES`) options.\n\n* Although the bitwise flag annotation indicates whether a read was marked as a duplicate, it does not identify the type of duplicate. To do this, a new tag called the duplicate type (DT) tag was recently added as an optional output of a SAM/BAM file. Invoking the **Tagging policy** ( `--TAGGING_POLICY`) option, you can instruct the program to mark all the duplicates (All), only the optical duplicates (OpticalOnly), or no duplicates (DontTag). The records within the output SAM/BAM file will have values for the 'DT' tag (depending on the invoked **TAGGING_POLICY** option), as either library/PCR-generated duplicates (LB), or sequencing-platform artifact duplicates (SQ). \n\n* This tool uses the **Read name regex** (`--READ_NAME_REGEX`) and the **Optical duplicate pixel distance** (`--OPTICAL_DUPLICATE_PIXEL_DISTANCE`) options as the primary methods to identify and differentiate duplicate types. Set **READ_NAME_REGEX** to null to skip optical duplicate detection, e.g. for RNA-seq or other data where duplicate sets are extremely large and estimating library complexity is not an aim. Note that without optical duplicate counts, library size estimation will be inaccurate.\n\n* Usage example:\n\n```\ngatk MarkDuplicates \\\n      --INPUT input.bam \\\n      --OUTPUT marked_duplicates.bam \\\n      --METRICS_FILE marked_dup_metrics.txt\n```\n\n###Changes Introduced by Seven Bridges\n\n* All output files will be prefixed using the **Output prefix** parameter. In case **Output prefix** is not provided, output prefix will be the same as the Sample ID metadata from the **Input SAM/BAM file**, if the Sample ID metadata exists. Otherwise, output prefix will be inferred from the **Input SAM/BAM** filename. This way, having identical names of the output files between runs is avoided. Moreover,  **dedupped** will be added before the extension of the output file name. \n\n* The user has a possibility to specify the output file format using the **Output file format** option. Otherwise, the output file format will be the same as the format of the input file.\n\n###Common Issues and Important Notes\n\n* None\n\n###Performance Benchmarking\n\nBelow is a table describing runtimes and task costs of **GATK MarkDuplicates** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Input size | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|\n|     RNA-Seq     |  1.8 GB |   3min   | ~0.02$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     |  5.3 GB |   9min   | ~0.06$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 8.8 GB |  16min  | ~0.11$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 17 GB |  30min  | ~0.20$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n###References\n\n[1] [GATK MarkDuplicates](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/picard_sam_markduplicates_MarkDuplicates.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "8",
        "name": "gatk_mergebamalignment_4_1_0_0",
        "description": "The **GATK MergeBamAlignment** tool is used for merging BAM/SAM alignment info from a third-party aligner with the data in an unmapped BAM file, producing a third BAM file that has alignment data (from the aligner) and all the remaining data from the unmapped BAM.\n\nMany alignment tools still require FASTQ format input. The unmapped BAM may contain useful information that will be lost in the conversion to FASTQ (meta-data like sample alias, library, barcodes, etc... as well as read-level tags.) This tool takes an unaligned BAM with meta-data, and the aligned BAM produced by calling [SamToFastq](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/picard_sam_SamToFastq.php) and then passing the result to an aligner. It produces a new SAM file that includes all aligned and unaligned reads and also carries forward additional read attributes from the unmapped BAM (attributes that are otherwise lost in the process of converting to FASTQ). The resulting file will be valid for use by Picard and GATK tools. The output may be coordinate-sorted, in which case the tags, NM, MD, and UQ will be calculated and populated, or query-name sorted, in which case the tags will not be calculated or populated [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of the page.*\n\n###Common Use Cases\n\n* The **GATK MergeBamAlignment** tool requires a SAM or BAM file on its **Aligned BAM/SAM file** (`--ALIGNED_BAM`) input, original SAM or BAM file of unmapped reads, which must be in queryname order on its **Unmapped BAM/SAM file** (`--UNMAPPED_BAM`) input and a reference sequence on its **Reference** (`--REFERENCE_SEQUENCE`) input. The tool generates a single BAM/SAM file on its **Output merged BAM/SAM file** output.\n\n* Usage example:\n\n```\ngatk MergeBamAlignment \\\\\n      --ALIGNED_BAM aligned.bam \\\\\n      --UNMAPPED_BAM unmapped.bam \\\\\n      --OUTPUT merged.bam \\\\\n      --REFERENCE_SEQUENCE reference_sequence.fasta\n```\n\n###Changes Introduced by Seven Bridges\n\n* The output file name will be prefixed using the **Output prefix** parameter. In case **Output prefix** is not provided, output prefix will be the same as the Sample ID metadata from **Input SAM/BAM file**, if the Sample ID metadata exists. Otherwise, output prefix will be inferred from the **Input SAM/BAM file** filename. This way, having identical names of the output files between runs is avoided. Moreover,  **merged** will be added before the extension of the output file name. \n\n* The user has a possibility to specify the output file format using the **Output file format** argument. Otherwise, the output file format will be the same as the format of the input aligned file.\n\n###Common Issues and Important Notes\n\n* Note:  This is not a tool for taking multiple BAM/SAM files and creating a bigger file by merging them. For that use-case, see [MergeSamFiles](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/picard_sam_MergeSamFiles.php).\n\n###Performance Benchmarking\n\nBelow is a table describing runtimes and task costs of **GATK MergeBamAlignment** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Aligned BAM/SAM size |  Unmapped BAM/SAM size | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|:----------:|:------:|:------:|------:|\n|     RNA-Seq     |  1.4 GB |  1.9 GB |   9min   | ~0.06$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     |  4.0 GB |  5.7 GB |   20min   | ~0.13$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 6.6 GB | 9.5 GB |  32min  | ~0.21$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 13 GB | 19 GB |  1h 4min  | ~0.42$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n###References\n\n[1] [GATK MergeBamAlignment](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/picard_sam_MergeBamAlignment.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "9",
        "name": "gatk_samtofastq_4_1_0_0",
        "description": "The **GATK SamToFastq** tool converts a SAM or BAM file to FASTQ.\n\nThis tool extracts read sequences and qualities from the input SAM/BAM file and writes them into the output file in Sanger FASTQ format.\n\nIn the RC mode (default is True), if the read is aligned and the alignment is to the reverse strand on the genome, the read sequence from input SAM file will be reverse-complemented prior to writing it to FASTQ in order to correctly restore the original read sequence as it was generated by the sequencer [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of the page.*\n\n###Common Use Cases\n\n* The **GATK SamToFastq** tool requires a BAM/SAM file on its **Input BAM/SAM file** (`--INPUT`) input. The tool generates a single-end FASTQ file on its **Output FASTQ file(s)** output if the input BAM/SAM file is single end. In case the input file is paired end, the tool outputs the first end of the pair FASTQ and the second end of the pair FASTQ on its **Output FASTQ file(s)** output, except when the **Interleave** (`--INTERLEAVE`) option is set to True. If the output is an interleaved FASTQ file, if paired, each line will have /1 or /2 to describe which end it came from.\n\n* The **GATK SamToFastq** tool supports an optional parameter  **Output by readgroup** (`--OUTPUT_BY_READGROUP`) which, when true, outputs a FASTQ file per read group (two FASTQ files per read group if the group is paired).\n\n* Usage example (input BAM file is single-end):\n\n```\ngatk SamToFastq \n     --INPUT input.bam\n     --FASTQ output.fastq\n```\n\n\n\n\n\n* Usage example (input BAM file is paired-end):\n\n```\ngatk SamToFastq \n     --INPUT input.bam\n     --FASTQ output.pe_1.fastq\n     --SECOND_END_FASTQ output.pe_2.fastq\n     --UNPAIRED_FASTQ unpaired.fastq\n\n```\n\n###Changes Introduced by Seven Bridges\n\n* The GATK SamToFastq tool is implemented to check if the input alignments file contains single-end or paired-end data and according to that generates different command lines for these two modes and thus produces appropriate output files on its **Output FASTQ file(s)** output (one FASTQ file in single-end mode and two FASTQ files if the input alignment file contains paired-end data). \n\n* All output files will be prefixed using the **Output prefix** parameter. In case the **Output prefix** is not provided, the output prefix will be the same as the Sample ID metadata from the **input SAM/BAM file**, if the Sample ID metadata exists. Otherwise, the output prefix will be inferred from the **Input SAM/BAM** filename. This way, having identical names of the output files between runs is avoided.\n\n* For paired-end read files, in order to successfully run alignment with STAR, this tool adds the appropriate **paired-end** metadata field in the output FASTQ files.\n\n###Common Issues and Important Notes\n\n* None\n\n###Performance Benchmarking\n\nBelow is a table describing runtimes and task costs of **GATK SamToFastq** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Input size | Paired-end | # of reads | Read length | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|:----------:|:------:|:------:|\n|     RNA-Seq     |  1.9 GB |     Yes    |     16M     |     101     |   4min   | ~0.03$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     |  5.7 GB |     Yes    |     50M     |     101     |   7min   | ~0.04$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 9.5 GB |     Yes    |     82M    |     101     |  10min  | ~0.07$ | c4.2xlarge (8 CPUs) | \n|     RNA-Seq     | 19 GB |     Yes    |     164M    |     101     |  20min  | ~0.13$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n\n###References\n\n[1] [GATK SamToFastq](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.12.0/picard_sam_SamToFastq)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "10",
        "name": "gatk_setnmmdanduqtags_4_1_0_0",
        "description": "The **GATK SetNmMdAndUqTags** tool takes in a coordinate-sorted SAM or BAM and calculatesthe NM, MD, and UQ tags by comparing it with the reference. \n\nThe **GATK SetNmMdAndUqTags**  may be needed when **GATK MergeBamAlignment** was run with **SORT_ORDER** other than `coordinate` and thus could not fix these tags. \n\n\n###Common Use Cases\nThe **GATK SetNmMdAndUqTags** tool  fixes NM, MD and UQ tags in SAM/BAM file **Input SAM/BAM file**   (`--INPUT`)  input. This tool takes in a coordinate-sorted SAM or BAM file and calculates the NM, MD, and UQ tags by comparing with the reference **Reference sequence** (`--REFERENCE_SEQUENCE`).\n\n* Usage example:\n\n```\njava -jar picard.jar SetNmMdAndUqTags\n     --REFERENCE_SEQUENCE=reference_sequence.fasta\n     --INPUT=sorted.bam\n```\n\n\n###Changes Introduced by Seven Bridges\n\n* Prefix of the output file is defined with the optional parameter **Output prefix**. If **Output prefix** is not provided, name of the sorted file is obtained from **Sample ID** metadata form the **Input SAM/BAM file**, if the **Sample ID** metadata exists. Otherwise, the output prefix will be inferred form the **Input SAM/BAM file** filename. \n\n\n\n###Common Issues and Important Notes\n\n* The **Input SAM/BAM file** must be coordinate sorted in order to run  **GATK SetNmMdAndUqTags**. \n* If specified, the MD and NM tags can be ignored and only the UQ tag be set. \n\n\n###References\n[1] [GATK SetNmMdAndUqTags home page](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.0.0/picard_sam_SetNmMdAndUqTags.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "11",
        "name": "gatk_sortsam_4_1_0_0",
        "description": "The **GATK SortSam** tool sorts the input SAM or BAM file by coordinate, queryname (QNAME), or some other property of the SAM record.\n\nThe **GATK SortOrder** of a SAM/BAM file is found in the SAM file header tag @HD in the field labeled SO.  For a coordinate\nsorted SAM/BAM file, read alignments are sorted first by the reference sequence name (RNAME) field using the reference\nsequence dictionary (@SQ tag).  Alignments within these subgroups are secondarily sorted using the left-most mapping\nposition of the read (POS).  Subsequent to this sorting scheme, alignments are listed arbitrarily.<\/p><p>For\nqueryname-sorted alignments, all alignments are grouped using the queryname field but the alignments are not necessarily\nsorted within these groups.  Reads having the same queryname are derived from the same template\n\n\n###Common Use Cases\n\nThe **GATK SortSam** tool requires a BAM/SAM file on its **Input SAM/BAM file**   (`--INPUT`)  input. The tool sorts input file in the order defined by (`--SORT_ORDER`) parameter. Available sort order options are `queryname`, `coordinate` and `duplicate`.  \n\n* Usage example:\n\n```\njava -jar picard.jar SortSam\n     --INPUT=input.bam \n     --SORT_ORDER=coordinate\n```\n\n\n###Changes Introduced by Seven Bridges\n\n* Prefix of the output file is defined with the optional parameter **Output prefix**. If **Output prefix** is not provided, name of the sorted file is obtained from **Sample ID** metadata from the **Input SAM/BAM file**, if the **Sample ID** metadata exists. Otherwise, the output prefix will be inferred form the **Input SAM/BAM file** filename. \n\n\n###Common Issues and Important Notes\n\n* None\n\n\n###Performance Benchmarking\nBelow is a table describing runtimes and task costs of **GATK SortSam** for a couple of different samples, executed on the AWS cloud instances:\n\n| Experiment type |  Input size | Paired-end | # of reads | Read length | Duration |  Cost | Instance (AWS) | \n|:--------------:|:------------:|:--------:|:-------:|:---------:|:----------:|:------:|:------:|\n|     WGS     |          |     Yes    |     16M     |     101     |   4min   | ~0.03$ | c4.2xlarge (8 CPUs) | \n|     WGS     |         |     Yes    |     50M     |     101     |   7min   | ~0.04$ | c4.2xlarge (8 CPUs) | \n|     WGS     |         |     Yes    |     82M    |     101     |  10min  | ~0.07$ | c4.2xlarge (8 CPUs) | \n|     WES     |         |     Yes    |     164M    |     101     |  20min  | ~0.13$ | c4.2xlarge (8 CPUs) |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n\n\n###References\n[1] [GATK SortSam home page](https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.12.0/picard_sam_SortSam.php)",
        "version": "4.1.0.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "12",
        "name": "sbg_lines_to_interval_list",
        "description": "This tools is used for splitting GATK sequence grouping file into subgroups.\n\n### Common Use Cases\n\nEach subgroup file contains intervals defined on single line in grouping file. Grouping file is output of GATKs **CreateSequenceGroupingTSV** script which is used in best practice workflows sush as **GATK Best Practice Germline Workflow**.",
        "version": "1.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "13",
        "name": "sbg_lines_to_interval_list_1",
        "description": "This tools is used for splitting GATK sequence grouping file into subgroups.\n\n### Common Use Cases\n\nEach subgroup file contains intervals defined on single line in grouping file. Grouping file is output of GATKs **CreateSequenceGroupingTSV** script which is used in best practice workflows sush as **GATK Best Practice Germline Workflow**.",
        "version": "1.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      }
    ]
  },
  "execution_domain": {
    "script": "cgc.sbgenomics.com/raw/admin/sbg-public-data/broad-best-practice-data-pre-processing-workflow-4-1-0-0/26",
    "script_driver": "Seven Bridges Common Workflow Language Executor",
    "software_prerequisites": [
      {
        "name": "Cancer Genomics Cloud Platform",
        "version": "2021-06-10",
        "uri": [
          {
            "uri": "cgc.sbgenomics.com",
            "access_time": "2021-06-10",
            "sha1_chksum": ""
          }
        ]
      },
      {
        "name": "cwltool",
        "version": "3.1.2",
        "uri": [
          {
            "uri": "https://github.com/common-workflow-language/cwltool",
            "access_time": "2021-06-10",
            "sha1_chksum": ""
          }
        ]
      }
    ],
    "external_data_endpoints": [],
    "environment_variables": []
  },
  "parametric_domain": [],
  "io_domain": {
    "input_subdomain": [
      {
        "uri": [
          {
            "filename": "",
            "uri": "",
            "access_time": ""
          }
        ]
      }
    ],
    "output_subdomain": [
      {
        "mediatype": "",
        "uri": [
          {
            "uri": "",
            "access_time": ""
          }
        ]
      }
    ]
  },
  "error_domain": {
    "empirical_error": [],
    "algorithmic_error": []
  }
}
